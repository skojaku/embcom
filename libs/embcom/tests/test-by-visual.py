# -*- coding: utf-8 -*-
# @Author: Sadamori Kojaku
# @Date:   2023-01-21 17:11:06
# @Last Modified by:   Sadamori Kojaku
# @Last Modified time: 2023-04-03 18:45:43
# %%
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
from scipy import sparse

import embcom


def fastRP(net, dim, window_size, beta=-1, s=3.0, edge_direction=False):
    """Fast Random Projection embedding.

    See https://arxiv.org/abs/1908.11512.

    Examples:

    Getting an embedding of a network
    >> emb = fastRP(net, dim=256, window_size=10)

    If the network is directed, one can construct two types of an embedding, one based on the neighbors
    connected by in-coming edges, and those by out-going edges. You can get the embedding by setting `edge_direction=True`.

    >> emb_out, emb_in = fastRP(net, dim=256, window_size=10, edge_direction=True)

    where `emb_out` is an embedding of nodes based on the edges going from the nodes, and `emb_in` is based on the in-coming edges.

    :param net: Adjacency matrix
    :type net: scipy.sparse matrix
    :param dim: Embedding dimension
    :type dim: int
    :param window_size: Window size
    :type window_size: int
    :param beta: degree normalization, defaults to -1. Ranges [0,1]. beta = -1 is the strongest normalization. beta = 0 means no regularization.
    :type beta: int, optional
    :param s: Inverse density of the random matrix, defaults to 3.0
    :type s: float, optional
    :param return-context: Set true to get the context embedding (which is an embedding generated by the transpose of the adjacency matrix).
    :type return_context: bool
    :return: embedding matrix
    :rtype: numpy.ndarray of (number of nodes, dimension)
    """

    n_nodes = net.shape[0]
    # Generate random matrix for random projection
    X = sparse.random(
        n_nodes,
        dim,
        density=1 / s,
        data_rvs=lambda x: np.sqrt(s) * (2 * np.random.randint(2, size=x) - 1),
    ).toarray()

    emb = _fastRP(net, dim, window_size, beta=beta, X=X.copy())

    if return_context:
        emb_cnt = _fastRP(
            net=sparse.csr_matrix(net.T),
            dim=dim,
            window_size=window_size,
            beta=beta,
            X=X.copy(),
        )
        return emb, emb_cnt
    return emb


def _fastRP(net, dim, window_size, X, beta=-1):

    # Get stats
    n_nodes = net.shape[0]
    outdeg = np.array(net.sum(axis=1)).reshape(-1)
    indeg = np.array(net.sum(axis=0)).reshape(-1)

    # Construct the transition matrix
    P = sparse.diags(1 / np.maximum(1, outdeg)) @ net  # Transition matrix
    L = sparse.diags(np.power(np.maximum(indeg.astype(float), 1.0), beta))

    # First random projection
    X0 = (P @ L) @ X.copy()  # to include the self-loops

    # h is an array for normalization
    h = np.ones((n_nodes, 1))
    h0 = h.copy()

    # Iterative projection
    for _ in range(window_size):
        X = P @ X + X0
        h = P @ h + h0

    # Normalization
    X = sparse.diags(1.0 / np.maximum(np.array(h).reshape(-1), 1e-8)) @ X
    return X


def load_airport_net():
    # Node attributes
    node_table = pd.read_csv(
        "https://raw.githubusercontent.com/skojaku/core-periphery-detection/master/data/node-table-airport.csv"
    )

    # Edge table
    edge_table = pd.read_csv(
        "https://raw.githubusercontent.com/skojaku/core-periphery-detection/master/data/edge-table-airport.csv"
    )
    # net = nx.adjacency_matrix(nx.from_pandas_edgelist(edge_table))

    net = sparse.csr_matrix(
        (
            edge_table["weight"].values,
            (edge_table["source"].values, edge_table["target"].values),
        ),
        shape=(node_table.shape[0], node_table.shape[0]),
    )

    s = ~pd.isna(node_table["region"])
    node_table = node_table[s]
    labels = node_table["region"].values
    net = net[s, :][:, s]
    return net, labels, node_table


net, labels, node_table = load_airport_net()

#
#
# Embedding
#
# model = embcom.NonBacktrackingNode2Vec()
# model.fit(net)
# emb = model.transform(dim=64)
dnet = sparse.triu(net) + net
emb, emb_inv = fastRP(dnet, dim=256, window_size=10, s=3, return_context=True)
emb = np.einsum("ij,i->ij", emb, 1 / np.linalg.norm(emb, axis=1))
emb_inv = np.einsum("ij,i->ij", emb_inv, 1 / np.linalg.norm(emb_inv, axis=1))
np.sum(emb * emb_inv, axis=1)

# %%
# Plot
#
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis

clf = LinearDiscriminantAnalysis(n_components=2)
cids = np.unique(labels, return_inverse=True)[1]
xy = clf.fit_transform(emb, cids)


plot_data = pd.DataFrame({"x": xy[:, 0], "y": xy[:, 1], "label": labels})

sns.scatterplot(data=plot_data, x="x", y="y", hue="label")
clf.score(emb, cids)

# %%
